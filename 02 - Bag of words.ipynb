{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from lib.utils import get_data, get_two_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "main_path = \"./\"\n",
    "dataset_filename = main_path+\"data/annotation_results__ann\"\n",
    "dataset_filename_2 = main_path+\"data/annotation_results\"\n",
    "dataset_wt_filename = main_path+\"data/sample_ann2_\"\n",
    "results_path = main_path+\"experiments_03/\"\n",
    "\n",
    "# classes\n",
    "Y_feat_names = [\"ns\", \"sens\"]\n",
    "\n",
    "# models\n",
    "models = [{\"name\": \"LR\", \"model\": LogisticRegression()},\n",
    "          {\"name\": \"lSVC\", \"model\": LinearSVC()},\n",
    "          #{\"name\": \"KNN\", \"model\": KNeighborsClassifier()},\n",
    "          {\"name\": \"RF\", \"model\": RandomForestClassifier(n_estimators=100, random_state=0)},\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "STEMMER = SnowballStemmer('english')\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "#stem_or_lemma: 1 for stemming, 2 for lemmatization, other for none\n",
    "def clean_text(text, remove_sw=False, stem_or_lemma=0):\n",
    "    def remove_url(txt):\n",
    "        return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "    \n",
    "    res = remove_url(text).lower().split()\n",
    "    # Remove english stop words\n",
    "    if remove_sw:\n",
    "        #stop_words = set(stopwords.words(\"english\"))\n",
    "        res = [word for word in res if not word in STOPWORDS]\n",
    "    if stem_or_lemma == 1: # stemming\n",
    "        #stemmer = SnowballStemmer('english')\n",
    "        res = [STEMMER.stem(word) for word in res]\n",
    "        #res = \" \".join([stemmer.stem(word) for word in res])\n",
    "    elif stem_or_lemma == 2: # lemmatization\n",
    "        #lemmatizer = WordNetLemmatizer()\n",
    "        res = [LEMMATIZER.lemmatize(word, pos='v') for word in res]\n",
    "\n",
    "    return res#.split() #remove_url(text).lower().split()\n",
    "\n",
    "def get_metrics(y_test, y_pred, Y_feat_names):\n",
    "    res = {}\n",
    "    res[\"accuracy\"] = metrics.accuracy_score(y_test, y_pred)\n",
    "    tmp = metrics.precision_score(y_test, y_pred, average=None)\n",
    "    for index, cls in enumerate(Y_feat_names):\n",
    "        res[\"precision_\"+cls] = tmp[index]\n",
    "    res[\"precision-micro\"] = metrics.precision_score(y_test, y_pred, average=\"micro\")\n",
    "    res[\"precision-macro\"] = metrics.precision_score(y_test, y_pred, average=\"macro\")\n",
    "    tmp = metrics.recall_score(y_test, y_pred, average=None)\n",
    "    for index, cls in enumerate(Y_feat_names):\n",
    "        res[\"recall_\"+cls] = tmp[index]\n",
    "    tmp = metrics.f1_score(y_test, y_pred, average=None)\n",
    "    for index, cls in enumerate(Y_feat_names):\n",
    "        res[\"f1_\"+cls] = tmp[index]\n",
    "    res[\"f1-micro\"] = metrics.f1_score(y_test, y_pred, average=\"micro\")\n",
    "    res[\"f1-macro\"] = metrics.f1_score(y_test, y_pred, average=\"macro\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Sens] BoW: Execution and Performances\n",
    "using as training sets Sens2 and Sens3, while as test sets Sens2, Sens3 and WH+TW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Agreement on 2 annotators\n",
      " - model: LR\n",
      "   time: /01, 00:00:13\n",
      " - model: lSVC\n",
      "   time: /01, 00:00:13\n",
      " - model: RF\n",
      "   time: /01, 00:01:33\n",
      "#### Agreement on 3 annotators\n",
      " - model: LR\n",
      "   time: /01, 00:00:12\n",
      " - model: lSVC\n",
      "   time: /01, 00:00:12\n",
      " - model: RF\n",
      "   time: /01, 00:00:38\n",
      "Experiment time in seconds: 185\n",
      "Experiment time: /01, 00:03:05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_ns</th>\n",
       "      <th>precision_sens</th>\n",
       "      <th>precision-micro</th>\n",
       "      <th>precision-macro</th>\n",
       "      <th>recall_ns</th>\n",
       "      <th>recall_sens</th>\n",
       "      <th>f1_ns</th>\n",
       "      <th>f1_sens</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>set</th>\n",
       "      <th>data</th>\n",
       "      <th>mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.721461</td>\n",
       "      <td>0.729647</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.721461</td>\n",
       "      <td>0.713712</td>\n",
       "      <td>0.874770</td>\n",
       "      <td>0.471471</td>\n",
       "      <td>0.795645</td>\n",
       "      <td>0.562724</td>\n",
       "      <td>0.721461</td>\n",
       "      <td>0.679184</td>\n",
       "      <td>test</td>\n",
       "      <td>ann2</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588933</td>\n",
       "      <td>0.621442</td>\n",
       "      <td>0.392943</td>\n",
       "      <td>0.588933</td>\n",
       "      <td>0.507192</td>\n",
       "      <td>0.860564</td>\n",
       "      <td>0.146882</td>\n",
       "      <td>0.721712</td>\n",
       "      <td>0.213834</td>\n",
       "      <td>0.588933</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>sample_01</td>\n",
       "      <td>ann2</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.581175</td>\n",
       "      <td>0.617106</td>\n",
       "      <td>0.366958</td>\n",
       "      <td>0.581175</td>\n",
       "      <td>0.492032</td>\n",
       "      <td>0.853196</td>\n",
       "      <td>0.138489</td>\n",
       "      <td>0.716196</td>\n",
       "      <td>0.201088</td>\n",
       "      <td>0.581175</td>\n",
       "      <td>0.458642</td>\n",
       "      <td>sample_02</td>\n",
       "      <td>ann2</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.584141</td>\n",
       "      <td>0.617958</td>\n",
       "      <td>0.371571</td>\n",
       "      <td>0.584141</td>\n",
       "      <td>0.494765</td>\n",
       "      <td>0.860748</td>\n",
       "      <td>0.133993</td>\n",
       "      <td>0.719421</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.584141</td>\n",
       "      <td>0.458190</td>\n",
       "      <td>sample_03</td>\n",
       "      <td>ann2</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590416</td>\n",
       "      <td>0.621066</td>\n",
       "      <td>0.391453</td>\n",
       "      <td>0.590416</td>\n",
       "      <td>0.506260</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.137290</td>\n",
       "      <td>0.724355</td>\n",
       "      <td>0.203285</td>\n",
       "      <td>0.590416</td>\n",
       "      <td>0.463820</td>\n",
       "      <td>sample_04</td>\n",
       "      <td>ann2</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.578095</td>\n",
       "      <td>0.612242</td>\n",
       "      <td>0.328273</td>\n",
       "      <td>0.578095</td>\n",
       "      <td>0.470258</td>\n",
       "      <td>0.869589</td>\n",
       "      <td>0.103717</td>\n",
       "      <td>0.718569</td>\n",
       "      <td>0.157631</td>\n",
       "      <td>0.578095</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>sample_07</td>\n",
       "      <td>ann3</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.610254</td>\n",
       "      <td>0.318141</td>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.464197</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.106715</td>\n",
       "      <td>0.713728</td>\n",
       "      <td>0.159820</td>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.436774</td>\n",
       "      <td>sample_08</td>\n",
       "      <td>ann3</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.581631</td>\n",
       "      <td>0.614654</td>\n",
       "      <td>0.346901</td>\n",
       "      <td>0.581631</td>\n",
       "      <td>0.480777</td>\n",
       "      <td>0.869958</td>\n",
       "      <td>0.112410</td>\n",
       "      <td>0.720354</td>\n",
       "      <td>0.169799</td>\n",
       "      <td>0.581631</td>\n",
       "      <td>0.445076</td>\n",
       "      <td>sample_09</td>\n",
       "      <td>ann3</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.581289</td>\n",
       "      <td>0.615830</td>\n",
       "      <td>0.357509</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>0.486669</td>\n",
       "      <td>0.861300</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>0.718169</td>\n",
       "      <td>0.185892</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>0.452031</td>\n",
       "      <td>sample_10</td>\n",
       "      <td>ann3</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.790873</td>\n",
       "      <td>0.787588</td>\n",
       "      <td>0.799045</td>\n",
       "      <td>0.790873</td>\n",
       "      <td>0.793316</td>\n",
       "      <td>0.906981</td>\n",
       "      <td>0.601918</td>\n",
       "      <td>0.843079</td>\n",
       "      <td>0.686613</td>\n",
       "      <td>0.790873</td>\n",
       "      <td>0.764846</td>\n",
       "      <td>ann2</td>\n",
       "      <td>ann3</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision_ns  precision_sens  precision-micro  precision-macro  \\\n",
       "0   0.721461      0.729647        0.697778         0.721461         0.713712   \n",
       "1   0.588933      0.621442        0.392943         0.588933         0.507192   \n",
       "2   0.581175      0.617106        0.366958         0.581175         0.492032   \n",
       "3   0.584141      0.617958        0.371571         0.584141         0.494765   \n",
       "4   0.590416      0.621066        0.391453         0.590416         0.506260   \n",
       "..       ...           ...             ...              ...              ...   \n",
       "67  0.578095      0.612242        0.328273         0.578095         0.470258   \n",
       "68  0.572961      0.610254        0.318141         0.572961         0.464197   \n",
       "69  0.581631      0.614654        0.346901         0.581631         0.480777   \n",
       "70  0.581289      0.615830        0.357509         0.581289         0.486669   \n",
       "71  0.790873      0.787588        0.799045         0.790873         0.793316   \n",
       "\n",
       "    recall_ns  recall_sens     f1_ns   f1_sens  f1-micro  f1-macro        set  \\\n",
       "0    0.874770     0.471471  0.795645  0.562724  0.721461  0.679184       test   \n",
       "1    0.860564     0.146882  0.721712  0.213834  0.588933  0.467773  sample_01   \n",
       "2    0.853196     0.138489  0.716196  0.201088  0.581175  0.458642  sample_02   \n",
       "3    0.860748     0.133993  0.719421  0.196960  0.584141  0.458190  sample_03   \n",
       "4    0.868852     0.137290  0.724355  0.203285  0.590416  0.463820  sample_04   \n",
       "..        ...          ...       ...       ...       ...       ...        ...   \n",
       "67   0.869589     0.103717  0.718569  0.157631  0.578095  0.438100  sample_07   \n",
       "68   0.859458     0.106715  0.713728  0.159820  0.572961  0.436774  sample_08   \n",
       "69   0.869958     0.112410  0.720354  0.169799  0.581631  0.445076  sample_09   \n",
       "70   0.861300     0.125600  0.718169  0.185892  0.581289  0.452031  sample_10   \n",
       "71   0.906981     0.601918  0.843079  0.686613  0.790873  0.764846       ann2   \n",
       "\n",
       "    data mod  \n",
       "0   ann2  LR  \n",
       "1   ann2  LR  \n",
       "2   ann2  LR  \n",
       "3   ann2  LR  \n",
       "4   ann2  LR  \n",
       "..   ...  ..  \n",
       "67  ann3  RF  \n",
       "68  ann3  RF  \n",
       "69  ann3  RF  \n",
       "70  ann3  RF  \n",
       "71  ann3  RF  \n",
       "\n",
       "[72 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_dict = []\n",
    "experiment_time = time.perf_counter()\n",
    "for ann in [2,3]:\n",
    "    print(\"#### Agreement on\", ann, \"annotators\")\n",
    "    # get data\n",
    "    train_loc = pd.read_csv(dataset_filename+str(ann)+\"_training.csv\")\n",
    "    test_loc = pd.read_csv(dataset_filename+str(ann)+\"_test.csv\")\n",
    "    # clean and stemmming\n",
    "    train_loc['text_cleaned_stem'] = train_loc['text'].map(lambda x: \" \".join(clean_text(x, remove_sw=True, stem_or_lemma=1)))\n",
    "    test_loc['text_cleaned_stem'] = test_loc['text'].map(lambda x: \" \".join(clean_text(x, remove_sw=True, stem_or_lemma=1)))\n",
    "    # bag of words\n",
    "    tfidfconverter = TfidfVectorizer()\n",
    "    X_train = tfidfconverter.fit_transform(train_loc['text_cleaned_stem']).toarray()\n",
    "    X_test = tfidfconverter.transform(test_loc['text_cleaned_stem']).toarray()\n",
    "    # classes\n",
    "    y_train = train_loc[\"class\"].tolist()\n",
    "    y_test = test_loc[\"class\"].tolist()\n",
    "    for model_dict in models:\n",
    "        model_name = model_dict[\"name\"]\n",
    "        model = model_dict[\"model\"]\n",
    "        model_time = time.perf_counter()\n",
    "        print(\" - model:\", model_name)\n",
    "        # training\n",
    "        model.fit(X_train, y_train)\n",
    "        # prediction\n",
    "        y_pred = model.predict(X_test)\n",
    "        # model evaluation on test set\n",
    "        met_dict_loc = get_metrics(y_test, y_pred, Y_feat_names)\n",
    "        met_dict_loc[\"set\"] = \"test\"\n",
    "        met_dict_loc[\"data\"] = \"ann\"+str(ann)\n",
    "        met_dict_loc[\"mod\"] = model_name\n",
    "        met_dict.append(met_dict_loc)\n",
    "        # model evaluation on other sets\n",
    "        for index in range(10):\n",
    "            test_loc_2 = pd.read_csv(dataset_wt_filename+((\"0\"+str(index+1))[-2:])+\".csv\")\n",
    "            test_loc_2['text_cleaned_stem'] = test_loc_2['text'].map(lambda x: \" \".join(clean_text(x, remove_sw=True, stem_or_lemma=1)))\n",
    "            X_test_loc = tfidfconverter.transform(test_loc_2['text_cleaned_stem']).toarray()\n",
    "            y_test_loc = test_loc_2[\"class\"].tolist()\n",
    "            y_pred_loc = model.predict(X_test_loc)\n",
    "            met_dict_loc = get_metrics(y_test_loc, y_pred_loc, Y_feat_names)\n",
    "            met_dict_loc[\"set\"] = \"sample_\"+str((\"0\"+str(index+1))[-2:])\n",
    "            met_dict_loc[\"data\"] = \"ann\"+str(ann)\n",
    "            met_dict_loc[\"mod\"] = model_name\n",
    "            met_dict.append(met_dict_loc)\n",
    "        other_ann = 2\n",
    "        if (ann == 2):\n",
    "            other_ann = 3\n",
    "        test_loc_2 = get_data(dataset_filename_2+\".csv\", lim=other_ann)\n",
    "        test_loc_2 = get_two_classes(test_loc_2)\n",
    "        test_loc_2['text_cleaned_stem'] = test_loc_2['text'].map(lambda x: \" \".join(clean_text(x, remove_sw=True, stem_or_lemma=1)))\n",
    "        X_test_loc = tfidfconverter.transform(test_loc_2['text_cleaned_stem']).toarray()\n",
    "        y_test_loc = test_loc_2[\"class\"].tolist()#pd.get_dummies(pd.DataFrame({\"class\": test_loc_2[\"class\"].tolist()})[\"class\"])[Y_feat_names].values\n",
    "        y_pred_loc = model.predict(X_test_loc)\n",
    "        met_dict_loc = get_metrics(y_test_loc, y_pred_loc, Y_feat_names)\n",
    "        met_dict_loc[\"set\"] = \"ann\"+str(other_ann)\n",
    "        met_dict_loc[\"data\"] = \"ann\"+str(ann)\n",
    "        met_dict_loc[\"mod\"] = model_name\n",
    "        met_dict.append(met_dict_loc)\n",
    "        model_time = time.perf_counter() - model_time\n",
    "        print(\"   time:\", time.strftime(\"/%d, %H:%M:%S\",time.gmtime(model_time)))\n",
    "\n",
    "experiment_time = time.perf_counter() - experiment_time\n",
    "print(\"Experiment time in seconds:\", int(experiment_time))\n",
    "print(\"Experiment time:\", time.strftime(\"/%d, %H:%M:%S\",time.gmtime(experiment_time)))\n",
    "\n",
    "met_dict_df_1 = pd.DataFrame(met_dict)\n",
    "met_dict_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_dict_df_1[\"set\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##  metrics on test set\n",
      "####  model: LR\n",
      "             metric      ann2      ann3\n",
      "0          accuracy  0.721461  0.779703\n",
      "1      precision_ns  0.729647  0.769716\n",
      "2    precision_sens  0.697778  0.816092\n",
      "3   precision-micro  0.721461  0.779703\n",
      "4   precision-macro  0.713712  0.792904\n",
      "5         recall_ns  0.874770  0.938462\n",
      "6       recall_sens  0.471471  0.493056\n",
      "7             f1_ns  0.795645  0.845754\n",
      "8           f1_sens  0.562724  0.614719\n",
      "9          f1-micro  0.721461  0.779703\n",
      "10         f1-macro  0.679184  0.730236\n",
      "####  model: lSVC\n",
      "             metric      ann2      ann3\n",
      "0          accuracy  0.705479  0.799505\n",
      "1      precision_ns  0.752212  0.835206\n",
      "2    precision_sens  0.620579  0.729927\n",
      "3   precision-micro  0.705479  0.799505\n",
      "4   precision-macro  0.686396  0.782566\n",
      "5         recall_ns  0.782689  0.857692\n",
      "6       recall_sens  0.579580  0.694444\n",
      "7             f1_ns  0.767148  0.846300\n",
      "8           f1_sens  0.599379  0.711744\n",
      "9          f1-micro  0.705479  0.799505\n",
      "10         f1-macro  0.683263  0.779022\n",
      "####  model: RF\n",
      "             metric      ann2      ann3\n",
      "0          accuracy  0.716895  0.774752\n",
      "1      precision_ns  0.722474  0.784512\n",
      "2    precision_sens  0.699531  0.747664\n",
      "3   precision-micro  0.716895  0.774752\n",
      "4   precision-macro  0.711002  0.766088\n",
      "5         recall_ns  0.882136  0.896154\n",
      "6       recall_sens  0.447447  0.555556\n",
      "7             f1_ns  0.794362  0.836625\n",
      "8           f1_sens  0.545788  0.637450\n",
      "9          f1-micro  0.716895  0.774752\n",
      "10         f1-macro  0.670075  0.737037\n",
      "##  metrics on the other set\n",
      "####  model: LR\n",
      "             metric  ann2 -> ann3  ann3 -> ann2\n",
      "0          accuracy      0.858873      0.735197\n",
      "1      precision_ns      0.842265      0.728933\n",
      "2    precision_sens      0.904541      0.756702\n",
      "3   precision-micro      0.858873      0.735197\n",
      "4   precision-macro      0.873403      0.742818\n",
      "5         recall_ns      0.960415      0.911402\n",
      "6       recall_sens      0.675900      0.448441\n",
      "7             f1_ns      0.897468      0.810019\n",
      "8           f1_sens      0.773682      0.563147\n",
      "9          f1-micro      0.858873      0.735197\n",
      "10         f1-macro      0.835575      0.686583\n",
      "####  model: lSVC\n",
      "             metric  ann2 -> ann3  ann3 -> ann2\n",
      "0          accuracy      0.926594      0.780833\n",
      "1      precision_ns      0.936388      0.800445\n",
      "2    precision_sens      0.908185      0.741715\n",
      "3   precision-micro      0.926594      0.780833\n",
      "4   precision-macro      0.922286      0.771080\n",
      "5         recall_ns      0.950423      0.860748\n",
      "6       recall_sens      0.883657      0.650779\n",
      "7             f1_ns      0.943353      0.829502\n",
      "8           f1_sens      0.895753      0.693278\n",
      "9          f1-micro      0.926594      0.780833\n",
      "10         f1-macro      0.919553      0.761390\n",
      "####  model: RF\n",
      "             metric  ann2 -> ann3  ann3 -> ann2\n",
      "0          accuracy      0.947850      0.790873\n",
      "1      precision_ns      0.941307      0.787588\n",
      "2    precision_sens      0.961107      0.799045\n",
      "3   precision-micro      0.947850      0.790873\n",
      "4   precision-macro      0.951207      0.793316\n",
      "5         recall_ns      0.980015      0.906981\n",
      "6       recall_sens      0.889889      0.601918\n",
      "7             f1_ns      0.960271      0.843079\n",
      "8           f1_sens      0.924128      0.686613\n",
      "9          f1-micro      0.947850      0.790873\n",
      "10         f1-macro      0.942200      0.764846\n",
      "\n",
      "##  agreement on 2 annotators: test on 10 samples\n",
      "####  model: LR\n",
      "             metric      mean       std\n",
      "0          accuracy  0.585910  0.002790\n",
      "1      precision_ns  0.618914  0.001438\n",
      "2    precision_sens  0.377615  0.008919\n",
      "3   precision-micro  0.585910  0.002790\n",
      "4   precision-macro  0.498265  0.005178\n",
      "5         recall_ns  0.862571  0.004653\n",
      "6       recall_sens  0.135671  0.004601\n",
      "7             f1_ns  0.720703  0.002326\n",
      "8           f1_sens  0.199594  0.005759\n",
      "9          f1-micro  0.585910  0.002790\n",
      "10         f1-macro  0.460148  0.003279\n",
      "####  model: lSVC\n",
      "             metric      mean       std\n",
      "0          accuracy  0.568534  0.004899\n",
      "1      precision_ns  0.623717  0.002834\n",
      "2    precision_sens  0.394340  0.009110\n",
      "3   precision-micro  0.568534  0.004899\n",
      "4   precision-macro  0.509029  0.005971\n",
      "5         recall_ns  0.764782  0.006906\n",
      "6       recall_sens  0.249161  0.005622\n",
      "7             f1_ns  0.687078  0.004274\n",
      "8           f1_sens  0.305349  0.006339\n",
      "9          f1-micro  0.568534  0.004899\n",
      "10         f1-macro  0.496213  0.004775\n",
      "####  model: RF\n",
      "             metric      mean       std\n",
      "0          accuracy  0.583366  0.003114\n",
      "1      precision_ns  0.618390  0.001857\n",
      "2    precision_sens  0.374546  0.011111\n",
      "3   precision-micro  0.583366  0.003114\n",
      "4   precision-macro  0.496468  0.006484\n",
      "5         recall_ns  0.854946  0.003968\n",
      "6       recall_sens  0.141397  0.006085\n",
      "7             f1_ns  0.717675  0.002261\n",
      "8           f1_sens  0.205269  0.007843\n",
      "9          f1-micro  0.583366  0.003114\n",
      "10         f1-macro  0.461472  0.004560\n",
      "\n",
      "##  agreement on 3 annotators: test on 10 samples\n",
      "####  model: LR\n",
      "             metric      mean       std\n",
      "0          accuracy  0.582111  0.002909\n",
      "1      precision_ns  0.612686  0.001551\n",
      "2    precision_sens  0.323976  0.012867\n",
      "3   precision-micro  0.582111  0.002909\n",
      "4   precision-macro  0.468331  0.007204\n",
      "5         recall_ns  0.884417  0.003472\n",
      "6       recall_sens  0.090138  0.003977\n",
      "7             f1_ns  0.723890  0.002108\n",
      "8           f1_sens  0.141026  0.005964\n",
      "9          f1-micro  0.582111  0.002909\n",
      "10         f1-macro  0.432458  0.003736\n",
      "####  model: lSVC\n",
      "             metric      mean       std\n",
      "0          accuracy  0.562864  0.003311\n",
      "1      precision_ns  0.614590  0.001997\n",
      "2    precision_sens  0.361941  0.007763\n",
      "3   precision-micro  0.562864  0.003311\n",
      "4   precision-macro  0.488265  0.004879\n",
      "5         recall_ns  0.789096  0.004230\n",
      "6       recall_sens  0.194694  0.005115\n",
      "7             f1_ns  0.690993  0.002632\n",
      "8           f1_sens  0.253179  0.005967\n",
      "9          f1-micro  0.562864  0.003311\n",
      "10         f1-macro  0.472086  0.003873\n",
      "####  model: RF\n",
      "             metric      mean       std\n",
      "0          accuracy  0.578642  0.003046\n",
      "1      precision_ns  0.613505  0.001914\n",
      "2    precision_sens  0.340104  0.013663\n",
      "3   precision-micro  0.578642  0.003046\n",
      "4   precision-macro  0.476804  0.007784\n",
      "5         recall_ns  0.864100  0.003730\n",
      "6       recall_sens  0.114089  0.007211\n",
      "7             f1_ns  0.717549  0.002049\n",
      "8           f1_sens  0.170832  0.009670\n",
      "9          f1-micro  0.578642  0.003046\n",
      "10         f1-macro  0.444191  0.005364\n"
     ]
    }
   ],
   "source": [
    "def get_df_stats_test(df, mod_name):\n",
    "    df_loc = df[(df[\"set\"] == \"test\") & (df[\"data\"] == \"ann2\") & (df[\"mod\"] == mod_name)][df.columns[:-3]]\n",
    "    df_res = df_loc.T.reset_index()\n",
    "    df_res.columns = [\"metric\", \"ann2\"]\n",
    "    df_loc = df[(df[\"set\"] == \"test\") & (df[\"data\"] == \"ann3\") & (df[\"mod\"] == mod_name)][df.columns[:-3]]\n",
    "    df_loc = df_loc.T.reset_index()\n",
    "    df_res[\"ann3\"] = df_loc[df_loc.columns[-1]]\n",
    "    return df_res\n",
    "\n",
    "def get_df_stats_test_rev(df, mod_name):\n",
    "    df_loc = df[(df[\"set\"] == \"ann3\") & (df[\"data\"] == \"ann2\") & (df[\"mod\"] == mod_name)][df.columns[:-3]]\n",
    "    df_res = df_loc.T.reset_index()\n",
    "    df_res.columns = [\"metric\", \"ann2 -> ann3\"]\n",
    "    df_loc = df[(df[\"set\"] == \"ann2\") & (df[\"data\"] == \"ann3\") & (df[\"mod\"] == mod_name)][df.columns[:-3]]\n",
    "    df_loc = df_loc.T.reset_index()\n",
    "    df_res[\"ann3 -> ann2\"] = df_loc[df_loc.columns[-1]]\n",
    "    return df_res\n",
    "\n",
    "def get_df_stats(df, ann, mod_name):\n",
    "    df_loc = df[(df[\"set\"].str[0] == 's') & (df[\"data\"] == \"ann\"+str(ann)) & (df[\"mod\"] == mod_name)][df.columns[:-3]]\n",
    "    df_res = df_loc.mean().reset_index(drop=False)\n",
    "    df_res[1] = df_loc.std().reset_index(drop=False)[0]\n",
    "    df_res.columns = [\"metric\", \"mean\", \"std\"]\n",
    "    return df_res\n",
    "\n",
    "model_names = [x[\"name\"] for x in models]\n",
    "\n",
    "print(\"##  metrics on test set\")\n",
    "for mod_name in model_names:\n",
    "    print(\"####  model:\", mod_name)\n",
    "    print(get_df_stats_test(met_dict_df_1, mod_name))\n",
    "\n",
    "print(\"##  metrics on the other set\")\n",
    "for mod_name in model_names:\n",
    "    print(\"####  model:\", mod_name)\n",
    "    print(get_df_stats_test_rev(met_dict_df_1, mod_name))\n",
    "    \n",
    "for ann in [2,3]:\n",
    "    print(\"\\n##  agreement on\", ann, \"annotators: test on 10 samples\")\n",
    "    for mod_name in model_names:\n",
    "        print(\"####  model:\", mod_name)\n",
    "        print(get_df_stats(met_dict_df_1, ann, mod_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [WH+TW] BoW: Execution and Performances\n",
    "using as training sets Sens2 and Sens3, while as test sets Sens2, Sens3 and WH+TW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - model: LR\n",
      "   time: /01, 04:22:32\n",
      " - model: lSVC\n",
      "   time: /01, 04:22:35\n",
      " - model: RF\n",
      "   time: /01, 04:22:38\n",
      " - model: LR\n",
      "   time: /01, 04:23:35\n",
      " - model: lSVC\n",
      "   time: /01, 04:23:39\n",
      " - model: RF\n",
      "   time: /01, 04:23:42\n",
      " - model: LR\n",
      "   time: /01, 04:24:37\n",
      " - model: lSVC\n",
      "   time: /01, 04:24:40\n",
      " - model: RF\n",
      "   time: /01, 04:24:43\n",
      " - model: LR\n",
      "   time: /01, 04:25:40\n",
      " - model: lSVC\n",
      "   time: /01, 04:25:43\n",
      " - model: RF\n",
      "   time: /01, 04:25:46\n",
      " - model: LR\n",
      "   time: /01, 04:26:43\n",
      " - model: lSVC\n",
      "   time: /01, 04:26:46\n",
      " - model: RF\n",
      "   time: /01, 04:26:49\n",
      " - model: LR\n",
      "   time: /01, 04:27:43\n",
      " - model: lSVC\n",
      "   time: /01, 04:27:46\n",
      " - model: RF\n",
      "   time: /01, 04:27:49\n",
      " - model: LR\n",
      "   time: /01, 04:28:43\n",
      " - model: lSVC\n",
      "   time: /01, 04:28:46\n",
      " - model: RF\n",
      "   time: /01, 04:28:49\n",
      " - model: LR\n",
      "   time: /01, 04:29:45\n",
      " - model: lSVC\n",
      "   time: /01, 04:29:48\n",
      " - model: RF\n",
      "   time: /01, 04:29:51\n",
      " - model: LR\n",
      "   time: /01, 04:30:46\n",
      " - model: lSVC\n",
      "   time: /01, 04:30:49\n",
      " - model: RF\n",
      "   time: /01, 04:30:52\n",
      " - model: LR\n",
      "   time: /01, 04:31:50\n",
      " - model: lSVC\n",
      "   time: /01, 04:31:53\n",
      " - model: RF\n",
      "   time: /01, 04:31:56\n",
      "Experiment time in seconds: 618\n",
      "Experiment time: /01, 00:10:18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_ns</th>\n",
       "      <th>precision_sens</th>\n",
       "      <th>precision-micro</th>\n",
       "      <th>precision-macro</th>\n",
       "      <th>recall_ns</th>\n",
       "      <th>recall_sens</th>\n",
       "      <th>f1_ns</th>\n",
       "      <th>f1_sens</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>set</th>\n",
       "      <th>data</th>\n",
       "      <th>mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.807078</td>\n",
       "      <td>0.801613</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.807078</td>\n",
       "      <td>0.810963</td>\n",
       "      <td>0.915285</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.854686</td>\n",
       "      <td>0.713073</td>\n",
       "      <td>0.807078</td>\n",
       "      <td>0.783880</td>\n",
       "      <td>test</td>\n",
       "      <td>sample_01</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.614291</td>\n",
       "      <td>0.347341</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.480816</td>\n",
       "      <td>0.859827</td>\n",
       "      <td>0.121403</td>\n",
       "      <td>0.716610</td>\n",
       "      <td>0.179920</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.448265</td>\n",
       "      <td>ann2</td>\n",
       "      <td>sample_01</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.591696</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.591696</td>\n",
       "      <td>0.472619</td>\n",
       "      <td>0.855111</td>\n",
       "      <td>0.117036</td>\n",
       "      <td>0.729269</td>\n",
       "      <td>0.169849</td>\n",
       "      <td>0.591696</td>\n",
       "      <td>0.449559</td>\n",
       "      <td>ann3</td>\n",
       "      <td>sample_01</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.843694</td>\n",
       "      <td>0.782748</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.813221</td>\n",
       "      <td>0.874770</td>\n",
       "      <td>0.735736</td>\n",
       "      <td>0.858951</td>\n",
       "      <td>0.758514</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.808733</td>\n",
       "      <td>test</td>\n",
       "      <td>sample_01</td>\n",
       "      <td>lSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.613875</td>\n",
       "      <td>0.362984</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.488429</td>\n",
       "      <td>0.754651</td>\n",
       "      <td>0.227518</td>\n",
       "      <td>0.677022</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.478367</td>\n",
       "      <td>ann2</td>\n",
       "      <td>sample_01</td>\n",
       "      <td>lSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.563605</td>\n",
       "      <td>0.618885</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.563605</td>\n",
       "      <td>0.498893</td>\n",
       "      <td>0.769018</td>\n",
       "      <td>0.229317</td>\n",
       "      <td>0.685832</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.563605</td>\n",
       "      <td>0.485773</td>\n",
       "      <td>ann2</td>\n",
       "      <td>sample_10</td>\n",
       "      <td>lSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.569698</td>\n",
       "      <td>0.637496</td>\n",
       "      <td>0.337705</td>\n",
       "      <td>0.569698</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.767102</td>\n",
       "      <td>0.213989</td>\n",
       "      <td>0.696320</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.569698</td>\n",
       "      <td>0.479147</td>\n",
       "      <td>ann3</td>\n",
       "      <td>sample_10</td>\n",
       "      <td>lSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.795662</td>\n",
       "      <td>0.811644</td>\n",
       "      <td>0.763699</td>\n",
       "      <td>0.795662</td>\n",
       "      <td>0.787671</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>0.669670</td>\n",
       "      <td>0.841171</td>\n",
       "      <td>0.713600</td>\n",
       "      <td>0.795662</td>\n",
       "      <td>0.777386</td>\n",
       "      <td>test</td>\n",
       "      <td>sample_10</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.570679</td>\n",
       "      <td>0.615087</td>\n",
       "      <td>0.360183</td>\n",
       "      <td>0.570679</td>\n",
       "      <td>0.487635</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.164868</td>\n",
       "      <td>0.702929</td>\n",
       "      <td>0.226198</td>\n",
       "      <td>0.570679</td>\n",
       "      <td>0.464563</td>\n",
       "      <td>ann2</td>\n",
       "      <td>sample_10</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.574642</td>\n",
       "      <td>0.631768</td>\n",
       "      <td>0.302987</td>\n",
       "      <td>0.574642</td>\n",
       "      <td>0.467378</td>\n",
       "      <td>0.811683</td>\n",
       "      <td>0.147507</td>\n",
       "      <td>0.710513</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.574642</td>\n",
       "      <td>0.454465</td>\n",
       "      <td>ann3</td>\n",
       "      <td>sample_10</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision_ns  precision_sens  precision-micro  precision-macro  \\\n",
       "0   0.807078      0.801613        0.820312         0.807078         0.810963   \n",
       "1   0.578779      0.614291        0.347341         0.578779         0.480816   \n",
       "2   0.591696      0.635714        0.309524         0.591696         0.472619   \n",
       "3   0.821918      0.843694        0.782748         0.821918         0.813221   \n",
       "4   0.554022      0.613875        0.362984         0.554022         0.488429   \n",
       "..       ...           ...             ...              ...              ...   \n",
       "85  0.563605      0.618885        0.378900         0.563605         0.498893   \n",
       "86  0.569698      0.637496        0.337705         0.569698         0.487600   \n",
       "87  0.795662      0.811644        0.763699         0.795662         0.787671   \n",
       "88  0.570679      0.615087        0.360183         0.570679         0.487635   \n",
       "89  0.574642      0.631768        0.302987         0.574642         0.467378   \n",
       "\n",
       "    recall_ns  recall_sens     f1_ns   f1_sens  f1-micro  f1-macro   set  \\\n",
       "0    0.915285     0.630631  0.854686  0.713073  0.807078  0.783880  test   \n",
       "1    0.859827     0.121403  0.716610  0.179920  0.578779  0.448265  ann2   \n",
       "2    0.855111     0.117036  0.729269  0.169849  0.591696  0.449559  ann3   \n",
       "3    0.874770     0.735736  0.858951  0.758514  0.821918  0.808733  test   \n",
       "4    0.754651     0.227518  0.677022  0.279713  0.554022  0.478367  ann2   \n",
       "..        ...          ...       ...       ...       ...       ...   ...   \n",
       "85   0.769018     0.229317  0.685832  0.285714  0.563605  0.485773  ann2   \n",
       "86   0.767102     0.213989  0.696320  0.261975  0.569698  0.479147  ann3   \n",
       "87   0.872928     0.669670  0.841171  0.713600  0.795662  0.777386  test   \n",
       "88   0.820041     0.164868  0.702929  0.226198  0.570679  0.464563  ann2   \n",
       "89   0.811683     0.147507  0.710513  0.198416  0.574642  0.454465  ann3   \n",
       "\n",
       "         data   mod  \n",
       "0   sample_01    LR  \n",
       "1   sample_01    LR  \n",
       "2   sample_01    LR  \n",
       "3   sample_01  lSVC  \n",
       "4   sample_01  lSVC  \n",
       "..        ...   ...  \n",
       "85  sample_10  lSVC  \n",
       "86  sample_10  lSVC  \n",
       "87  sample_10    RF  \n",
       "88  sample_10    RF  \n",
       "89  sample_10    RF  \n",
       "\n",
       "[90 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_dict = []\n",
    "experiment_time = time.perf_counter()\n",
    "for index in range(10):\n",
    "    # get data\n",
    "    train_loc = pd.read_csv(dataset_wt_filename+((\"0\"+str(index+1))[-2:])+\"_training.csv\")\n",
    "    test_loc = pd.read_csv(dataset_wt_filename+((\"0\"+str(index+1))[-2:])+\"_test.csv\")\n",
    "    # clean and stemmming\n",
    "    train_loc['text_cleaned_stem'] = train_loc['text'].map(lambda x: \" \".join(clean_text(x, remove_sw=True, stem_or_lemma=1)))\n",
    "    test_loc['text_cleaned_stem'] = test_loc['text'].map(lambda x: \" \".join(clean_text(x, remove_sw=True, stem_or_lemma=1)))\n",
    "    # bag of words\n",
    "    tfidfconverter = TfidfVectorizer()\n",
    "    X_train = tfidfconverter.fit_transform(train_loc['text_cleaned_stem']).toarray()\n",
    "    X_test = tfidfconverter.transform(test_loc['text_cleaned_stem']).toarray()\n",
    "    # classes\n",
    "    y_train = train_loc[\"class\"].tolist()\n",
    "    y_test = test_loc[\"class\"].tolist()\n",
    "    for model_dict in models:\n",
    "        model_name = model_dict[\"name\"]\n",
    "        model = model_dict[\"model\"]\n",
    "        model_time = time.perf_counter()\n",
    "        print(\" - model:\", model_name)\n",
    "        # training\n",
    "        model.fit(X_train, y_train)\n",
    "        # prediction\n",
    "        y_pred = model.predict(X_test)\n",
    "        # model evaluation on test set\n",
    "        met_dict_loc = get_metrics(y_test, y_pred, Y_feat_names)\n",
    "        met_dict_loc[\"set\"] = \"test\"\n",
    "        met_dict_loc[\"data\"] = \"sample_\"+str((\"0\"+str(index+1))[-2:])\n",
    "        met_dict_loc[\"mod\"] = model_name\n",
    "        met_dict.append(met_dict_loc)\n",
    "        # model evaluation on other sets\n",
    "        for ann in [2,3]:\n",
    "            # get data\n",
    "            test_loc_2 = get_data(dataset_filename_2+\".csv\", lim=ann)\n",
    "            test_loc_2 = get_two_classes(test_loc_2)\n",
    "            test_loc_2['text_cleaned_stem'] = test_loc_2['text'].map(lambda x: \" \".join(clean_text(x, remove_sw=True, stem_or_lemma=1)))\n",
    "            X_test_loc = tfidfconverter.transform(test_loc_2['text_cleaned_stem']).toarray()\n",
    "            y_test_loc = test_loc_2[\"class\"].tolist()\n",
    "            y_pred_loc = model.predict(X_test_loc)\n",
    "            met_dict_loc = get_metrics(y_test_loc, y_pred_loc, Y_feat_names)\n",
    "            met_dict_loc[\"set\"] = \"ann\"+str(ann)\n",
    "            met_dict_loc[\"data\"] = \"sample_\"+str((\"0\"+str(index+1))[-2:])\n",
    "            met_dict_loc[\"mod\"] = model_name\n",
    "            met_dict.append(met_dict_loc)\n",
    "            model_time = time.perf_counter() - model_time\n",
    "        print(\"   time:\", time.strftime(\"/%d, %H:%M:%S\",time.gmtime(model_time)))\n",
    "\n",
    "experiment_time = time.perf_counter() - experiment_time\n",
    "print(\"Experiment time in seconds:\", int(experiment_time))\n",
    "print(\"Experiment time:\", time.strftime(\"/%d, %H:%M:%S\",time.gmtime(experiment_time)))\n",
    "\n",
    "met_dict_df_2 = pd.DataFrame(met_dict)\n",
    "met_dict_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##  metrics on test set of 10 samples\n",
      "####  model: LR\n",
      "             metric      mean       std\n",
      "0          accuracy  0.820662  0.009044\n",
      "1      precision_ns  0.815262  0.012567\n",
      "2    precision_sens  0.834209  0.014993\n",
      "3   precision-micro  0.820662  0.009044\n",
      "4   precision-macro  0.824735  0.008688\n",
      "5         recall_ns  0.919337  0.010301\n",
      "6       recall_sens  0.659760  0.030396\n",
      "7             f1_ns  0.864071  0.005945\n",
      "8           f1_sens  0.736316  0.017841\n",
      "9          f1-micro  0.820662  0.009044\n",
      "10         f1-macro  0.800194  0.011624\n",
      "\n",
      "##  10 samples using as test set the agreement on 2 annotators\n",
      "             metric      mean       std\n",
      "0          accuracy  0.584073  0.003560\n",
      "1      precision_ns  0.616099  0.001657\n",
      "2    precision_sens  0.357317  0.011550\n",
      "3   precision-micro  0.584073  0.003560\n",
      "4   precision-macro  0.486708  0.006598\n",
      "5         recall_ns  0.871597  0.007625\n",
      "6       recall_sens  0.116157  0.007280\n",
      "7             f1_ns  0.721898  0.003300\n",
      "8           f1_sens  0.175229  0.009032\n",
      "9          f1-micro  0.584073  0.003560\n",
      "10         f1-macro  0.448564  0.004356\n",
      "\n",
      "##  10 samples using as test set the agreement on 3 annotators\n",
      "             metric      mean       std\n",
      "0          accuracy  0.592116  0.004592\n",
      "1      precision_ns  0.634613  0.002687\n",
      "2    precision_sens  0.297666  0.019605\n",
      "3   precision-micro  0.592116  0.004592\n",
      "4   precision-macro  0.466139  0.011128\n",
      "5         recall_ns  0.862183  0.007272\n",
      "6       recall_sens  0.105471  0.011252\n",
      "7             f1_ns  0.731087  0.003481\n",
      "8           f1_sens  0.155657  0.014629\n",
      "9          f1-micro  0.592116  0.004592\n",
      "10         f1-macro  0.443372  0.007749\n",
      "####  model: lSVC\n",
      "             metric      mean       std\n",
      "0          accuracy  0.819977  0.010296\n",
      "1      precision_ns  0.846255  0.013064\n",
      "2    precision_sens  0.774623  0.012996\n",
      "3   precision-micro  0.819977  0.010296\n",
      "4   precision-macro  0.810439  0.010556\n",
      "5         recall_ns  0.867403  0.010050\n",
      "6       recall_sens  0.742643  0.026143\n",
      "7             f1_ns  0.856618  0.007703\n",
      "8           f1_sens  0.758077  0.016000\n",
      "9          f1-micro  0.819977  0.010296\n",
      "10         f1-macro  0.807348  0.011631\n",
      "\n",
      "##  10 samples using as test set the agreement on 2 annotators\n",
      "             metric      mean       std\n",
      "0          accuracy  0.560673  0.004641\n",
      "1      precision_ns  0.615623  0.003230\n",
      "2    precision_sens  0.367036  0.012200\n",
      "3   precision-micro  0.560673  0.004641\n",
      "4   precision-macro  0.491329  0.007710\n",
      "5         recall_ns  0.774028  0.009148\n",
      "6       recall_sens  0.213459  0.014248\n",
      "7             f1_ns  0.685772  0.004139\n",
      "8           f1_sens  0.269817  0.014203\n",
      "9          f1-micro  0.560673  0.004641\n",
      "10         f1-macro  0.477795  0.007288\n",
      "\n",
      "##  10 samples using as test set the agreement on 3 annotators\n",
      "             metric      mean       std\n",
      "0          accuracy  0.562383  0.009128\n",
      "1      precision_ns  0.632316  0.007299\n",
      "2    precision_sens  0.317908  0.027968\n",
      "3   precision-micro  0.562383  0.009128\n",
      "4   precision-macro  0.475112  0.017620\n",
      "5         recall_ns  0.763836  0.008074\n",
      "6       recall_sens  0.199377  0.026994\n",
      "7             f1_ns  0.691842  0.005344\n",
      "8           f1_sens  0.244902  0.028575\n",
      "9          f1-micro  0.562383  0.009128\n",
      "10         f1-macro  0.468372  0.016052\n",
      "####  model: RF\n",
      "             metric      mean       std\n",
      "0          accuracy  0.799087  0.009196\n",
      "1      precision_ns  0.815647  0.010338\n",
      "2    precision_sens  0.766893  0.015084\n",
      "3   precision-micro  0.799087  0.009196\n",
      "4   precision-macro  0.791270  0.010017\n",
      "5         recall_ns  0.873481  0.011254\n",
      "6       recall_sens  0.677778  0.023220\n",
      "7             f1_ns  0.843502  0.006954\n",
      "8           f1_sens  0.719342  0.014912\n",
      "9          f1-micro  0.799087  0.009196\n",
      "10         f1-macro  0.781422  0.010562\n",
      "\n",
      "##  10 samples using as test set the agreement on 2 annotators\n",
      "             metric      mean       std\n",
      "0          accuracy  0.573862  0.003226\n",
      "1      precision_ns  0.615954  0.001177\n",
      "2    precision_sens  0.363509  0.005607\n",
      "3   precision-micro  0.573862  0.003226\n",
      "4   precision-macro  0.489732  0.003388\n",
      "5         recall_ns  0.828679  0.008469\n",
      "6       recall_sens  0.159173  0.006806\n",
      "7             f1_ns  0.706641  0.003603\n",
      "8           f1_sens  0.221310  0.006683\n",
      "9          f1-micro  0.573862  0.003226\n",
      "10         f1-macro  0.463976  0.002492\n",
      "\n",
      "##  10 samples using as test set the agreement on 3 annotators\n",
      "             metric      mean       std\n",
      "0          accuracy  0.577583  0.005596\n",
      "1      precision_ns  0.632741  0.002708\n",
      "2    precision_sens  0.305991  0.012617\n",
      "3   precision-micro  0.577583  0.005596\n",
      "4   precision-macro  0.469366  0.007642\n",
      "5         recall_ns  0.817832  0.009527\n",
      "6       recall_sens  0.144668  0.008268\n",
      "7             f1_ns  0.713464  0.004918\n",
      "8           f1_sens  0.196370  0.009371\n",
      "9          f1-micro  0.577583  0.005596\n",
      "10         f1-macro  0.454917  0.005429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_df_stats_2(df):\n",
    "    print(\"##  metrics on test set of 10 samples\")\n",
    "    for mod_name in model_names:\n",
    "        print(\"####  model:\", mod_name)\n",
    "        #print(get_df_stats_test(met_dict_df_1, mod_name))\n",
    "        df_loc = df[(df[\"set\"] == \"test\") & (df[\"mod\"] == mod_name)][df.columns[:-2]]\n",
    "        df_res = df_loc.mean().reset_index(drop=False)\n",
    "        df_res[1] = df_loc.std().reset_index(drop=False)[0]\n",
    "        df_res.columns = [\"metric\", \"mean\", \"std\"]\n",
    "        print(df_res)\n",
    "        for ann in [2,3]:\n",
    "            print(\"\\n##  10 samples using as test set the agreement on\", ann, \"annotators\")\n",
    "            #print(\"####  model:\", mod_name)\n",
    "            df_loc = df[(df[\"set\"] == \"ann\"+str(ann)) & (df[\"mod\"] == mod_name)][df.columns[:-3]]\n",
    "            df_res = df_loc.mean().reset_index(drop=False)\n",
    "            df_res[1] = df_loc.std().reset_index(drop=False)[0]\n",
    "            df_res.columns = [\"metric\", \"mean\", \"std\"]\n",
    "            print(df_res)\n",
    "    return\n",
    "\n",
    "get_df_stats_2(met_dict_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_dict_df_1.to_csv(results_path+\"bow_agreements.csv\", index=False)\n",
    "met_dict_df_2.to_csv(results_path+\"bow_samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
